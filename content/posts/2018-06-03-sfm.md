---
type: post
template: post
title: Structure from Motion
date: 2018-06-03 22:00:00 -0700
updated: 2018-06-03 22:00:00 -0700
slug: sfm
tags:
  - photogrammetry
  - computer-vision
summary: My experiences with building 3D models from photographs using the Structure from Motion pipeline.
---

A favorite music video of mine is [Holly Herndon's][holly] Chorus,
directed by [Akihiko Taniguchi][director]. During the video, the camera
pans around 3D models of cluttered desks. About half way
through, objects start floating around the desks and spinning wildly. It is great.

<p> <iframe width="640" height="350" style="max-width: 100%"
src="https://www.youtube-nocookie.com/embed/nHujh3yA3BE"
frameborder="0" allow="autoplay; encrypted-media"
allowfullscreen></iframe> </p>

The models in this video look like they were created using a
[photogrammetric][wiki] technique called [structure from motion][sfm]
(SfM). The concept of structure from motion photogrammetry is fairly
straightforward. Given photographs of an object from many different
angles it is possible for an algorithm to construct a 3D model of the
object.

I set out to use structure from motion to create a 3D model of my desk
as a tribute to the Holly Herndon video. Sadly, the lighting in my
apartment was too uneven to create a good result. Instead, I cycled
around my neighborhood to look for a new subject. I ended up choosing
an obelisk-ish stone object (I think at one point it may have held a
plaque) on a path near the Elbow River.

<div uk-alert class="uk-alert-primary">
	Check out the completed model below. See
	if you can spot the Edvard Munch graffiti!
</div>

<p><iframe width="640" height="480" style="max-width: 100%" src="https://sketchfab.com/models/8d5b6290f295463dbc3dc4d135076014/embed?preload=1" frameborder="0" allowvr allowfullscreen mozallowfullscreen="true" webkitallowfullscreen="true" onmousewheel=""></iframe></p>

## How does it work?

If you are curious about the theory of structure from motion,
[Schonberger and Frahm's 2016 paper (pdf)][sfm-revisited] has a
step-by-step summary of the pipeline. The algorithm consists of two
main sections:

1. **Correspondence Search:** First, [features][feature] are
   identified in the input photographs using a descriptor such as
   [SIFT][sift]. The identified features in each image are compared to
   each other image to determine which photographs overlap.
2. **Incremental Reconstruction:** During this phase, a model is
   initialized and new images are added incrementally. Camera position
   is determined by solving the [perspective-n-point][pnp] problem and
   new point locations are added via triangulation. After each
   iteration a [bundle adjustment][ba] step is performed to refine the
   model and reduce noise.

## Open source workflow

There are plenty of excellent photogrammetry tutorials on the
internet. If you don't have a programming background, don't
despair. There is no requirement to understand any algorithms or write
any code. I followed along with a [blog post][tutorial] by [Jesse
Spielman][heavyimage] and a [video tutorial][vid] by [Phil
Nolan][phil] while building my model.

Commercial software photogrammetry exists, but it is possible to build
a great model using a completely free stack. For this model I used:

- [Darktable][darktable] - photo editing
- [VisualSfM][vsfm] - structure from motion
- [Meshlab][meshlab] - point cloud preprocessing, surface
reconstruction, and texturing
- [Sketchfab][sketchfab] - postprocessing and sharing

As long as you have taken [adequate input photos][tested] and chosen
an appropriate subject then VisualSfM will handle all of the structure
for motion heavy lifting with a few button clicks.

Meshlab has built in tools for all of the surface reconstruction and
texturing steps in the process required after SfM. Getting the correct
sequence of preprocessing tools and reconstruction parameters takes a
bit of trial and error.

Below are a few screenshots and videos I captured during the process:

![photos][obelisk-img]

<figure>
	<video src="/images/sfm/sfm.webm" loop autobuffer autoplay controls muted style="max-width:100%; border:1px solid #e1e1e1;" width="600">
	Sorry, your browser doesn't support html5 videos =(
	</video>
		<figcaption>
		VisualSFM solving the scene in real time (video)
	</ficaption>
</figure>

<figure>
	<video src="/images/sfm/obelisk-fade.webm" loop autobuffer autoplay controls muted style="max-width:100%" width="600">
	Sorry, your browser doesn't support html5 videos =(
	</video>
	<figcaption>
		Point cloud fading to input photo (video)
	</ficaption>
</figure>

![obelisk texture][texture-img]

## Wrap up

I didn't have immediate success with this photogrammetry project. The
first handful of models I tried failed, sometimes horribly. It took
consistently lit input photos and stumbling on the right meshing
parameters to get a result I was happy with. There are a few things I
wish I knew when I got started:

- Taking good input photos and picking an appropriate subject is key
- Make sure to experiment with the parameters in the meshing step,
  especially *minimum number of samples* if your data is noisy
- Read and watch plenty of tutorials before diving head first into the
  process. There is an active photogrammetry hobbyist scene and lots
  of resources out there

Structure from motion is a sophisticated computer vision algorithm
with a lot going on under the hood. I didn't dig deep, but I tried to
get a base understanding of what is going on. To follow up on this
project, I am planning on circling back to learn more about computer
vision fundamentals.

[holly]: http://www.hollyherndon.com/
[director]: http://okikata.org/
[wiki]: https://en.wikipedia.org/wiki/Photogrammetry
[sfm]: https://en.wikipedia.org/wiki/Structure_from_motion
[sketchfab]: https://sketchfab.com/
[sfm-revisited]: https://demuc.de/papers/schoenberger2016sfm.pdf
[feature]: https://en.wikipedia.org/wiki/Feature_(computer_vision)
[sift]: https://en.wikipedia.org/wiki/Scale-invariant_feature_transform
[pnp]: https://en.wikipedia.org/wiki/Perspective-n-Point
[ba]: https://en.wikipedia.org/wiki/Bundle_adjustment
[darktable]: https://www.darktable.org/
[tutorial]: http://wedidstuff.heavyimage.com/index.php/2013/07/12/open-source-photogrammetry-workflow/
[heavyimage]: http://www.heavyimage.com/
[phil]: http://philnolan3d.com/
[vid]: https://youtu.be/D6eqW6yk50k
[tested]: http://www.tested.com/art/makers/460142-art-photogrammetry-how-take-your-photos/
[vsfm]: http://ccwu.me/vsfm/
[meshlab]: http://www.meshlab.net/

[obelisk-img]: /images/sfm/obelisk-thumbnails.png "Input photo thumbnails"
[texture-img]: /images/sfm/obelisk-texture.png "UV texture map and final model"
